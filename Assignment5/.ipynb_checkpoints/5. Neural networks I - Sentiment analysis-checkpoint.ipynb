{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc9be56",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b3b52",
   "metadata": {},
   "source": [
    "In this exercise we use the IMDb-dataset, which we will use to perform a sentiment analysis. The code below assumes that the data is placed in the same folder as this notebook. We see that the reviews are loaded as a pandas dataframe, and print the beginning of the first few reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67da3bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "                                                   0\n",
      "0  bromwell high is a cartoon comedy . it ran at ...\n",
      "1  story of a man who has unnatural feelings for ...\n",
      "2  homelessness  or houselessness as george carli...\n",
      "3  airport    starts as a brand new luxury    pla...\n",
      "4  brilliant over  acting by lesley ann warren . ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "reviews = pd.read_csv('reviews.txt', header=None)\n",
    "labels = pd.read_csv('labels.txt', header=None)\n",
    "Y = (labels=='positive').astype(np.int_)\n",
    "\n",
    "print(type(reviews))\n",
    "print(reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b981dc7b-a334-47a8-ab9c-619826aec25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  0\n",
       "2  1\n",
       "3  0\n",
       "4  1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4982b946",
   "metadata": {},
   "source": [
    "**(a)** Split the reviews and labels in test, train and validation sets. The train and validation sets will be used to train your model and tune hyperparameters, the test set will be saved for testing. Use the `CountVectorizer` from `sklearn.feature_extraction.text` to create a Bag-of-Words representation of the reviews. Only use the 10,000 most frequent words (use the `max_features`-parameter of `CountVectorizer`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf07ee9",
   "metadata": {},
   "source": [
    "**(b)** Explore the representation of the reviews. How is a single word represented? How about a whole review?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2638fce",
   "metadata": {},
   "source": [
    "**(c)** Train a neural network with a single hidden layer on the dataset, tuning the relevant hyperparameters to optimize accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd327a6",
   "metadata": {},
   "source": [
    "**(d)** Test your sentiment-classifier on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd44ee62",
   "metadata": {},
   "source": [
    "**(e)** Use the classifier to classify a few sentences you write yourselves. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6a63b1-4278-491f-837e-d6b8bb23b39e",
   "metadata": {},
   "source": [
    "#### (a) Split the reviews and labels in test, train and validation sets. The train and validation sets will be used to train your model and tune hyperparameters, the test set will be saved for testing. Use the CountVectorizer from sklearn.feature_extraction.text to create a Bag-of-Words representation of the reviews. Only use the 10,000 most frequent words (use the max_features-parameter of CountVectorizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ada4849-8cb8-47db-9969-1330b764c932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (17500, 10000)\n",
      "Validation set shape: (3750, 10000)\n",
      "Test set shape: (3750, 10000)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Load the data\n",
    "reviews = pd.read_csv('reviews.txt', header=None, names=['review'])\n",
    "labels = pd.read_csv('labels.txt', header=None, names=['label'])\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    reviews['review'], labels['label'], test_size=0.3, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Create the Bag-of-Words representation using CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=10000)\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_val_bow = vectorizer.transform(X_val)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "# Print the shapes of the datasets\n",
    "print(\"Train set shape:\", X_train_bow.shape)\n",
    "print(\"Validation set shape:\", X_val_bow.shape)\n",
    "print(\"Test set shape:\", X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e45b51-99b9-4e74-9853-c29962182c1e",
   "metadata": {},
   "source": [
    "### (b) Explore the representation of the reviews. How is a single word represented? How about a whole review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6175719e-9965-43be-8b99-736086ca74d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'good' is represented as index: 3841\n",
      "Original review: this movie is a joke and must be one of the worst movies stallone ever made . this is a typical   s movie where you have one man destroying the whole army by himself .  first blood pt .   is very similar to schwarzenegger  s  commando   but there you have arnold killing the terrorist while here you have a specific nation showed as the bad guys . this movie is a typical american anti  soviet propaganda . true  this was the peak of the cold war  but i  m sick of having communists or the nazis always being shown as the enemy . there are so many american movies that have this one thing in common . why can  t there a movie that show americans as the enemy  who  s going to believe that one lone soldier will destroy the whole army  do you really think that something like this would have really happened  by the looks of it  an average  brain washed american viewer certainly would .  \n",
      "Bag-of-Words representation (non-zero entries):   (0, 284)\t1\n",
      "  (0, 301)\t3\n",
      "  (0, 302)\t1\n",
      "  (0, 321)\t1\n",
      "  (0, 328)\t1\n",
      "  (0, 379)\t1\n",
      "  (0, 451)\t1\n",
      "  (0, 469)\t2\n",
      "  (0, 471)\t1\n",
      "  (0, 501)\t3\n",
      "  (0, 611)\t1\n",
      "  (0, 665)\t1\n",
      "  (0, 749)\t1\n",
      "  (0, 803)\t1\n",
      "  (0, 810)\t1\n",
      "  (0, 947)\t1\n",
      "  (0, 1052)\t1\n",
      "  (0, 1200)\t2\n",
      "  (0, 1213)\t2\n",
      "  (0, 1254)\t1\n",
      "  (0, 1404)\t1\n",
      "  (0, 1678)\t1\n",
      "  (0, 1733)\t1\n",
      "  (0, 1748)\t1\n",
      "  (0, 2412)\t1\n",
      "  :\t:\n",
      "  (0, 8433)\t1\n",
      "  (0, 8934)\t1\n",
      "  (0, 8952)\t4\n",
      "  (0, 8954)\t11\n",
      "  (0, 8974)\t3\n",
      "  (0, 8986)\t1\n",
      "  (0, 8988)\t1\n",
      "  (0, 8996)\t6\n",
      "  (0, 9079)\t2\n",
      "  (0, 9257)\t1\n",
      "  (0, 9301)\t2\n",
      "  (0, 9530)\t1\n",
      "  (0, 9556)\t1\n",
      "  (0, 9665)\t1\n",
      "  (0, 9686)\t1\n",
      "  (0, 9688)\t1\n",
      "  (0, 9770)\t1\n",
      "  (0, 9775)\t1\n",
      "  (0, 9784)\t1\n",
      "  (0, 9786)\t2\n",
      "  (0, 9793)\t1\n",
      "  (0, 9811)\t1\n",
      "  (0, 9907)\t1\n",
      "  (0, 9912)\t2\n",
      "  (0, 9970)\t4\n",
      "Feature indices with non-zero values: [ 284  301  302  321  328  379  451  469  471  501  611  665  749  803\n",
      "  810  947 1052 1200 1213 1254 1404 1678 1733 1748 2412 2414 2590 2942\n",
      " 3062 3413 3828 3987 4047 4099 4101 4168 4206 4474 4709 4722 4819 4933\n",
      " 5181 5270 5283 5376 5422 5449 5848 5849 5892 5941 5955 6167 6210 6241\n",
      " 6474 6932 7171 7753 8044 8048 8052 8066 8095 8248 8258 8272 8315 8340\n",
      " 8433 8934 8952 8954 8974 8986 8988 8996 9079 9257 9301 9530 9556 9665\n",
      " 9686 9688 9770 9775 9784 9786 9793 9811 9907 9912 9970]\n",
      "Counts of the corresponding words: [ 1  3  1  1  1  1  1  2  1  3  1  1  1  1  1  1  1  2  2  1  1  1  1  1\n",
      "  1  1  1  2  1  1  1  1  1  5  1  1  1  1  4  1  1  1  1  1  1  1  1  1\n",
      "  4  2  1  1  1  4  4  1  1  1  2  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  4 11  3  1  1  6  2  1  2  1  1  1  1  1  1  1  1  2  1  1  1  2  4]\n"
     ]
    }
   ],
   "source": [
    "# Get the feature names (words in the vocabulary)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Single word representation\n",
    "word_index = feature_names.tolist().index('good')  # Example: word \"good\"\n",
    "print(f\"The word 'good' is represented as index: {word_index}\")\n",
    "\n",
    "# Representation of a single review\n",
    "sample_review = X_train.iloc[0]  # First review in the training set\n",
    "sample_review_bow = vectorizer.transform([sample_review])\n",
    "\n",
    "print(f\"Original review: {sample_review}\")\n",
    "print(f\"Bag-of-Words representation (non-zero entries): {sample_review_bow}\")\n",
    "print(f\"Feature indices with non-zero values: {sample_review_bow.indices}\")\n",
    "print(f\"Counts of the corresponding words: {sample_review_bow.data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361194a6-6470-4203-a812-6f3b88f28418",
   "metadata": {},
   "source": [
    "### (c) Train a neural network with a single hidden layer on the dataset, tuning the relevant hyperparameters to optimize accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3455ec74-d0ff-4b4b-a092-24f57ca6459d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\shankar\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\shankar\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\shankar\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\shankar\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shankar\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\shankar\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shankar\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\shankar\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\shankar\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shankar\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ad81a21f-1658-465c-afee-8d73b6f4d64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 128.3367, Validation Accuracy: 0.8672\n",
      "Epoch 2, Loss: 106.8789, Validation Accuracy: 0.8827\n",
      "Epoch 3, Loss: 101.7261, Validation Accuracy: 0.8779\n",
      "Epoch 4, Loss: 98.4121, Validation Accuracy: 0.8747\n",
      "Epoch 5, Loss: 96.7635, Validation Accuracy: 0.8709\n",
      "Epoch 6, Loss: 94.5402, Validation Accuracy: 0.8765\n",
      "Epoch 7, Loss: 94.5927, Validation Accuracy: 0.8749\n",
      "Epoch 8, Loss: 93.7861, Validation Accuracy: 0.8712\n",
      "Epoch 9, Loss: 93.9275, Validation Accuracy: 0.8715\n",
      "Epoch 10, Loss: 93.1081, Validation Accuracy: 0.8736\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_bow.toarray(), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor((y_train == \"positive\").astype(int).values, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val_bow.toarray(), dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor((y_val == \"positive\").astype(int).values, dtype=torch.long)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "\n",
    "# Define the neural network\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "input_size = 10000\n",
    "hidden_size = 128\n",
    "output_size = 2  \n",
    "model = SentimentClassifier(input_size, hidden_size, output_size)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Validation accuracy\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            outputs = model(X_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "    val_accuracy = correct / total\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d509228-c25e-4e83-b375-62207aeaf8d6",
   "metadata": {},
   "source": [
    "### (d) Test your sentiment-classifier on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0e558cd4-cb2e-4780-8b74-edd4fc6c12ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8744\n"
     ]
    }
   ],
   "source": [
    "# Convert test data to PyTorch tensors\n",
    "X_test_tensor = torch.tensor(X_test_bow.toarray(), dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor((y_test == \"positive\").astype(int).values, dtype=torch.long)\n",
    "\n",
    "# Test accuracy\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "test_accuracy = correct / total\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5781ab64-684b-4cca-a4f3-9510492c5d75",
   "metadata": {},
   "source": [
    "### (e) Use the classifier to classify a few sentences you write yourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2894726d-4900-442b-a506-20dd41e9e73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: This movie was fantastic! I loved it.\n",
      "Predicted Sentiment: positive\n",
      "\n",
      "Sentence: Absolutely terrible. I hated every second of it.\n",
      "Predicted Sentiment: negative\n",
      "\n",
      "Sentence: It was okay, not great but not bad either.\n",
      "Predicted Sentiment: negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Custom sentences\n",
    "custom_sentences = [\n",
    "    \"This movie was fantastic! I loved it.\",\n",
    "    \"Absolutely terrible. I hated every second of it.\",\n",
    "    \"It was okay, not great but not bad either.\"\n",
    "]\n",
    "\n",
    "# Transform sentences to Bag-of-Words representation\n",
    "custom_bow = vectorizer.transform(custom_sentences)\n",
    "custom_tensor = torch.tensor(custom_bow.toarray(), dtype=torch.float32)\n",
    "\n",
    "# Predict sentiment\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(custom_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Map predictions to labels\n",
    "predicted_labels = [\"positive\" if label == 1 else \"negative\" for label in predicted]\n",
    "for sentence, label in zip(custom_sentences, predicted_labels):\n",
    "    print(f\"Sentence: {sentence}\\nPredicted Sentiment: {label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde87fe-833a-4d46-8956-6537b8551008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
