{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bafe240-5583-43b9-86b0-4366a08c288c",
   "metadata": {},
   "source": [
    "# 4. Mushroom foraging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31181875-5c48-4e3b-9ba3-a0febdb9ebb2",
   "metadata": {},
   "source": [
    "The [mushroom dataset](https://www.kaggle.com/datasets/dhinaharp/mushroom-dataset) contains data about approximately 60000 mushrooms, and your task is to classify them as either edible or poisonous. You can read about the features [here](https://www.kaggle.com/datasets/uciml/mushroom-classification) and import the data using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41995351-199c-4a0e-81eb-c882e435dcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "df = pd.read_csv('secondary_data.csv', delimiter = ';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab16bc8-44af-4f86-97f8-ae339dbbbd67",
   "metadata": {},
   "source": [
    "It's up to you how you approach this data, but at a minimum, your analysis should include:\n",
    "\n",
    "* Informed **data preparation**.\n",
    "* 2 different classification models, one of which must be **logistic regression**.\n",
    "* A discussion of which **performance metric** is most relevant for the evaluation of your models.\n",
    "* 2 different **validation methodologies** used to tune hyperparameters.\n",
    "* **Confusion matrices** for your models, and associated comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0615d12d-6dea-4c85-8549-6fe98f566dc2",
   "metadata": {},
   "source": [
    "## Informed Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "66ac48ed-970f-47ef-8ff6-9effb7f3d3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (61069, 21)\n",
      "\n",
      "Data types:\n",
      " class                    object\n",
      "cap-diameter            float64\n",
      "cap-shape                object\n",
      "cap-surface              object\n",
      "cap-color                object\n",
      "does-bruise-or-bleed     object\n",
      "gill-attachment          object\n",
      "gill-spacing             object\n",
      "gill-color               object\n",
      "stem-height             float64\n",
      "stem-width              float64\n",
      "stem-root                object\n",
      "stem-surface             object\n",
      "stem-color               object\n",
      "veil-type                object\n",
      "veil-color               object\n",
      "has-ring                 object\n",
      "ring-type                object\n",
      "spore-print-color        object\n",
      "habitat                  object\n",
      "season                   object\n",
      "dtype: object\n",
      "\n",
      "Missing values per column:\n",
      " class                       0\n",
      "cap-diameter                0\n",
      "cap-shape                   0\n",
      "cap-surface             14120\n",
      "cap-color                   0\n",
      "does-bruise-or-bleed        0\n",
      "gill-attachment          9884\n",
      "gill-spacing            25063\n",
      "gill-color                  0\n",
      "stem-height                 0\n",
      "stem-width                  0\n",
      "stem-root               51538\n",
      "stem-surface            38124\n",
      "stem-color                  0\n",
      "veil-type               57892\n",
      "veil-color              53656\n",
      "has-ring                    0\n",
      "ring-type                2471\n",
      "spore-print-color       54715\n",
      "habitat                     0\n",
      "season                      0\n",
      "dtype: int64\n",
      "\n",
      "Target class distribution:\n",
      " class\n",
      "p    33888\n",
      "e    27181\n",
      "Name: count, dtype: int64\n",
      "Data preparation is complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"\\nData types:\\n\", df.dtypes)\n",
    "print(\"\\nMissing values per column:\\n\", df.isnull().sum())\n",
    "\n",
    "# Check the distribution of the target variable\n",
    "print(\"\\nTarget class distribution:\\n\", df['class'].value_counts())\n",
    "\n",
    "# Fill missing values with 'unknown'\n",
    "df.fillna(\"unknown\", inplace=True)\n",
    "\n",
    "# Encode categorical variables using Label Encoding\n",
    "label_encoders = {}\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df.drop(columns=['class'])  \n",
    "y = df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data preparation is complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb29a0c0-603a-4639-8cc2-072904958fee",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c32ddade-b6be-4bf1-b199-0f60139e7efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Performance:\n",
      "Accuracy: 0.6633\n",
      "Precision: 0.6826\n",
      "Recall: 0.7455\n",
      "F1 Score: 0.7126\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Scaling the features for Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict and evaluate the Logistic Regression model\n",
    "y_pred_lr = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the Logistic Regression model performance\n",
    "print(\"\\nLogistic Regression Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_lr):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f937731a-0467-456d-a200-442363ef405a",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d12f9928-6276-430f-abbf-468cfc699ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Performance:\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the Random Forest model\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest model performance\n",
    "print(\"\\nRandom Forest Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_rf):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50cf7a0-8d50-40b3-9b77-a31b1358c77b",
   "metadata": {},
   "source": [
    "##  Performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a1483d19-b70f-4902-93cd-09ed222e6efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Logistic Regression Performance Metrics:\n",
      "Accuracy : 0.6633\n",
      "Precision: 0.6826\n",
      "Recall   : 0.7455\n",
      "F1 Score : 0.7126\n",
      "\n",
      " Random Forest Performance Metrics:\n",
      "Accuracy : 1.0000\n",
      "Precision: 1.0000\n",
      "Recall   : 1.0000\n",
      "F1 Score : 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_model(name, y_true, y_pred):\n",
    "    print(f\"\\n {name} Performance Metrics:\")\n",
    "    print(f\"Accuracy : {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Recall   : {recall_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"F1 Score : {f1_score(y_true, y_pred):.4f}\")\n",
    "\n",
    "# Evaluate original models\n",
    "evaluate_model(\"Logistic Regression\", y_test, y_pred_lr)\n",
    "evaluate_model(\"Random Forest\", y_test, y_pred_rf)\n",
    "\n",
    "# Evaluate tuned Logistic Regression if you ran GridSearchCV\n",
    "#evaluate_model(\"Tuned Logistic Regression\", y_test, y_pred_best_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2e8e44-e93d-4090-9225-e4012b1ffbc9",
   "metadata": {},
   "source": [
    "##### For the mushroom classification task, recall is the most critical performance metric.  Misclassifying a poisonous mushroom as edible (a false negative) could be dangerous or even fatal. By focusing on recall, we ensure the model catches as many poisonous mushrooms as possible, even if it sometimes mislabels edible ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1fc69d-56e9-4bc9-856f-4e751f1d5832",
   "metadata": {},
   "source": [
    "## Validation Methodology : Train-Test Methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6caa7455-78ad-4e3a-ab94-3765cbcd8d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuned Logistic Regression Performance:\n",
      "Accuracy: 0.6636\n",
      "Precision: 0.6827\n",
      "Recall: 0.7459\n",
      "F1 Score: 0.7129\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameters for GridSearchCV (for Logistic Regression)\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1, 10],  # Regularization parameter\n",
    "    'solver': ['liblinear', 'saga']  # Solver options\n",
    "}\n",
    "\n",
    "# Create the Logistic Regression model and apply GridSearchCV\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(max_iter=500), param_grid_lr, cv=5, scoring='recall')\n",
    "grid_search_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best model and evaluate it\n",
    "best_lr_model = grid_search_lr.best_estimator_\n",
    "y_pred_best_lr = best_lr_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nTuned Logistic Regression Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_best_lr):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_best_lr):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_best_lr):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_best_lr):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf9410f-ec54-41b8-b5f9-b18d35970d02",
   "metadata": {},
   "source": [
    "## Validation Methodology : Cross-Validation Methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65168b06-50b4-4d7c-a061-849d9cd0caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('secondary_data.csv', delimiter=';')\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)# Define hyperparameters for GridSearchCV (for Random Forest)\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200], \n",
    "    'max_depth': [10, 20, None], \n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Create the Random Forest model and apply GridSearchCV\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, scoring='recall')\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and evaluate it\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "y_pred_best_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "print(\"\\nTuned Random Forest Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_best_rf):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_best_rf):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_best_rf):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_best_rf):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb6cf4-0213-408e-9a4e-8b279b591699",
   "metadata": {},
   "source": [
    "## Confusion metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f839ef6b-4228-49d4-a7bd-911d8a6fbd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Confusion Matrix for Logistic Regression\n",
    "conf_matrix_lr = confusion_matrix(y_test, y_pred_best_lr)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix_lr, annot=True, fmt='d', cmap='Blues', xticklabels=['Edible', 'Poisonous'], yticklabels=['Edible', 'Poisonous'])\n",
    "plt.title('Confusion Matrix: Logistic Regression')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix for Random Forest\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_pred_best_rf)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix_rf, annot=True, fmt='d', cmap='Greens', xticklabels=['Edible', 'Poisonous'], yticklabels=['Edible', 'Poisonous'])\n",
    "plt.title('Confusion Matrix: Random Forest')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05530f6a-f760-46f5-bead-99e46c23ddef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
